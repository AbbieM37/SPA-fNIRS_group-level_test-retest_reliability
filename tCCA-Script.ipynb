{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Import common libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import MNE processing\n",
    "import mne\n",
    "from mne.preprocessing.nirs import optical_density, beer_lambert_law\n",
    "from mne.preprocessing.nirs import optical_density, beer_lambert_law, scalp_coupling_index, temporal_derivative_distribution_repair\n",
    "\n",
    "\n",
    "# Import MNE-NIRS processing\n",
    "from mne_nirs.statistics import run_glm\n",
    "from mne_nirs.experimental_design import make_first_level_design_matrix\n",
    "from mne_nirs.statistics import statsmodels_to_results\n",
    "from mne_nirs.channels import get_short_channels, get_long_channels\n",
    "from mne_nirs.channels import picks_pair_to_idx\n",
    "from mne_nirs.visualisation import plot_glm_group_topo\n",
    "from mne_nirs.datasets import fnirs_motor_group\n",
    "from mne_nirs.visualisation import plot_glm_surface_projection\n",
    "from mne_nirs.io.fold import fold_channel_specificity\n",
    "\n",
    "# Import MNE-BIDS processing\n",
    "from mne_bids import BIDSPath, read_raw_bids, get_entity_vals\n",
    "\n",
    "# Import StatsModels\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Import Plotting Library\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "from itertools import compress\n",
    "from sklearn.cross_decomposition import CCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import signal\n",
    "\n",
    "# Import other randoms\n",
    "import h5py\n",
    "from scipy import interpolate\n",
    "\n",
    "import ipyevents\n",
    "import pyvistaqt\n",
    "import ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "root = \"Define your own root based on where the data set is saved\"\n",
    "\n",
    "print(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Make sure your data is in BIDS format before running the script\n",
    "\n",
    "dataset = BIDSPath(root= \"Define your own root based on where the data set is saved\"\n",
    ", \n",
    "                   datatype=\"nirs\", suffix=\"nirs\", extension=\".snirf\")\n",
    "print(dataset.directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create lowpass filter\n",
    "from scipy.signal import butter, filtfilt\n",
    "def lowpass_filter(data, cutoff, fs, order=4):\n",
    "    nyquist = 0.5 * fs  # Nyquist frequency\n",
    "    normal_cutoff = cutoff / nyquist\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    filtered_data = filtfilt(b, a, data)\n",
    "    return filtered_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lag\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "\n",
    "# Find optimal lag between two signals based on cross-correlation\n",
    "def find_optimal_lag(nirs_data, aux_data, max_lag_samples=30):\n",
    "    nirs = nirs_data - np.mean(nirs_data)\n",
    "    aux = aux_data - np.mean(aux_data)\n",
    "    correlation = np.correlate(aux, nirs, mode='full')\n",
    "    lags = signal.correlation_lags(len(aux), len(nirs), mode='full')\n",
    "\n",
    "    # Limit lags to a specific window\n",
    "    valid_idx = (lags >= 0) & (lags <= max_lag_samples)\n",
    "    correlation = correlation[valid_idx]\n",
    "    lags = lags[valid_idx]\n",
    "\n",
    "    best_lag = lags[np.argmax(np.abs(correlation))]\n",
    "    best_corr = correlation[np.argmax(np.abs(correlation))]\n",
    "\n",
    "    return best_lag, best_corr\n",
    "\n",
    "# Create a lagged version of a dataset\n",
    "def create_lagged_matrix(data, lags):\n",
    "    return np.hstack([np.roll(data, shift=lag, axis=0) for lag in lags])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the individual analysis function to be used for each individual dataset\n",
    "# Set up necessary parameters for design matrix and GLM process-- this is specific for the SS Correction + tCCA denoising model\n",
    "\n",
    "def individual_analysis(bids_path, ID):\n",
    "    \n",
    "    # Load in data; remove unnecessary annotations and rename meaningful annotations\n",
    "    raw_intensity = mne.io.read_raw_snirf(fname=bids_path, verbose=False, optode_frame=\"mri\")\n",
    "    raw_intensity.annotations.delete(raw_intensity.annotations.description == '15')\n",
    "    raw_intensity.annotations.rename({'1': 'speech', '2': 'speech', '3': 'silence'})\n",
    "    \n",
    "    # sanitize event names\n",
    "    raw_intensity.annotations.description[:] = [d.replace('/', '_') for d in raw_intensity.annotations.description]\n",
    "\n",
    "    # Convert signal to haemoglobin and resample; remove poorly coupled optodes\n",
    "    raw_od = optical_density(raw_intensity)\n",
    "    sci = scalp_coupling_index(raw_od, h_freq=1.35, h_trans_bandwidth=0.1)\n",
    "    raw_od.info['bads'] = list(compress(raw_od.ch_names, sci < 0.7))\n",
    "    raw_od.interpolate_bads()\n",
    "    raw_od.resample(.6)\n",
    "    raw_haemo = beer_lambert_law(raw_od, ppf=0.1)\n",
    "\n",
    "    # IDing short chans\n",
    "    sht_chans = get_short_channels(raw_haemo)\n",
    "    raw_haemo = get_long_channels(raw_haemo)\n",
    "\n",
    "    # Create a design matrix\n",
    "    design_matrix = make_first_level_design_matrix(\n",
    "        raw_haemo, drift_model='cosine', high_pass=0.015, hrf_model='spm', stim_dur=6.0)\n",
    "    \n",
    "    # Append short channels mean to design matrix\n",
    "    design_matrix[\"ShortHbO\"] = np.mean(sht_chans.copy().pick(picks=\"hbo\").get_data(), axis=0)\n",
    "    design_matrix[\"ShortHbR\"] = np.mean(sht_chans.copy().pick(picks=\"hbr\").get_data(), axis=0)\n",
    "\n",
    "    \n",
    "    physio_cols = []\n",
    "    # loading in aux signals\n",
    "    for n in [18, 19, 20, 21, 22, 23]:\n",
    "        with h5py.File(bids_path, 'r') as dat:\n",
    "            aux = np.array(dat.get(f'nirs/aux{n}/dataTimeSeries'))\n",
    "            aux_time = np.array(dat.get(f'nirs/aux{n}/time'))\n",
    "            fqs = np.argmax(aux_time > 1)\n",
    "            filtered_aux = lowpass_filter(aux, cutoff=0.5, fs=fqs, order=4)\n",
    "            aux_data_interp = interpolate.interp1d(aux_time, filtered_aux, axis=0, bounds_error=False, fill_value='extrapolate')\n",
    "            aux_data_matched_to_fnirs = aux_data_interp(raw_haemo.times)\n",
    "            signal_name = np.array(dat.get(f'nirs/aux{n}/name'))[0].decode()\n",
    "            design_matrix[signal_name] = aux_data_matched_to_fnirs\n",
    "            physio_cols.append(signal_name)\n",
    "\n",
    "    physio_data = design_matrix[physio_cols].values\n",
    "    physio_data = StandardScaler().fit_transform(physio_data)\n",
    "\n",
    "    fs = 1 / np.median(np.diff(raw_haemo.times))\n",
    "    max_lag_seconds = 10\n",
    "    max_lag_samples = int(max_lag_seconds * fs)\n",
    "    lags = np.arange(-max_lag_samples, max_lag_samples + 1)\n",
    "\n",
    "    # below is where we identify each \"best lag\" for each aux signal\n",
    "    for i, col in enumerate(physio_cols):\n",
    "        best_lag, _ = find_optimal_lag(physio_data[:, 0], physio_data[:, i], max_lag_samples=max_lag_samples)        \n",
    "        physio_data[:, i] = np.roll(physio_data[:, i], best_lag)\n",
    "\n",
    "    physio_lagged = create_lagged_matrix(physio_data, lags)\n",
    "    valid_idx = max(abs(lags))\n",
    "    physio_lagged = physio_lagged[valid_idx:-valid_idx]\n",
    "\n",
    "    fnirs_data = raw_haemo.copy().pick(picks=[\"hbo\", \"hbr\"]).get_data().T\n",
    "    fnirs_data = StandardScaler().fit_transform(fnirs_data)\n",
    "    fnirs_lagged = fnirs_data[valid_idx:-valid_idx]\n",
    "    \n",
    "\n",
    "    #CCA component\n",
    "    cca = CCA(n_components=2, tol=0.3)\n",
    "    physio_c, fnirs_c = cca.fit_transform(physio_lagged, fnirs_lagged)\n",
    "\n",
    "    # Matching lengths of nirs and physio data; making sure raw_haemo contains both and is the same length\n",
    "    # Only best lags used\n",
    "    start = valid_idx\n",
    "    end = -valid_idx if valid_idx > 0 else None\n",
    "    design_matrix = design_matrix.iloc[start:end].reset_index(drop=True)\n",
    "    raw_haemo.crop(tmin=raw_haemo.times[start], tmax=raw_haemo.times[end - 1] if end is not None else raw_haemo.times[-1])\n",
    "\n",
    "    # Pair physiology data to design matrix\n",
    "    design_matrix[\"CCA1\"] = physio_c[:, 0]\n",
    "    design_matrix[\"CCA2\"] = physio_c[:, 1]\n",
    "\n",
    "    glm_est = run_glm(raw_haemo, design_matrix)\n",
    "\n",
    "    # ID channels to group together for ROIs\n",
    "    IFG = [[1,1],[2,1],[3,1],[4,1],[3,2],[4,2],[9,8],[10,8],[11,8],[12,8],[11,9],[12,9]]\n",
    "    HG = [[5,4],[5,3],[5,5],[6,4],[6,3],[6,5],[13,11],[13,10],[13,12],[14,11],[14,10],[14,12]]\n",
    "    PT = [[6,6],[6,7],[7,5],[7,7],[8,6],[8,7],[14,13],[14,14],[15,12],[15,14],[16,13],[16,14]]\n",
    "\n",
    "    # Define ROI groups to pair NIRS data to based on channels\n",
    "    groups = dict(IFG = picks_pair_to_idx(raw_haemo, IFG),\n",
    "                  PT = picks_pair_to_idx(raw_haemo, PT),\n",
    "                  HG = picks_pair_to_idx(raw_haemo, HG)) \n",
    "    \n",
    "    # Extract channel metrics\n",
    "    cha = glm_est.to_dataframe()\n",
    "\n",
    "    # Compute region of interest results from channel data\n",
    "    roi = glm_est.to_dataframe_region_of_interest(groups, design_matrix.columns, demographic_info=True)\n",
    "\n",
    "    \n",
    "    # Define contrasts for conditions\n",
    "    contrast_matrix = np.eye(design_matrix.shape[1])\n",
    "    basic_conts = dict([(column, contrast_matrix[i])\n",
    "                        for i, column in enumerate(design_matrix.columns)])\n",
    "    contrast_SpchSil = basic_conts['speech'] - basic_conts['silence']\n",
    "\n",
    "    # Compute defined contrast\n",
    "    contrast = glm_est.compute_contrast(contrast_SpchSil)\n",
    "    con = contrast.to_dataframe()\n",
    "\n",
    "    # Add the participant ID to the dataframes\n",
    "    roi[\"ID\"] = cha[\"ID\"] = con[\"ID\"] = ID\n",
    "\n",
    "    # Convert to uM for nicer plotting below.\n",
    "    cha[\"theta\"] = [t * 1.e6 for t in cha[\"theta\"]]\n",
    "    roi[\"theta\"] = [t * 1.e6 for t in roi[\"theta\"]]\n",
    "    con[\"effect\"] = [t * 1.e6 for t in con[\"effect\"]]\n",
    "\n",
    "    return raw_haemo, roi, cha, con, design_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_roi = pd.DataFrame()  # To store region of interest results\n",
    "df_cha = pd.DataFrame()  # To store channel level results\n",
    "df_con = pd.DataFrame()  # To store channel level contrast results\n",
    "\n",
    "# Create path to file based on experiment info\n",
    "for sub in [1, 2, 3, 4 ,5, 7, 8, 9, 11, 12, 13, 14, 17, 18, 19]: # change range values to specify the number of subject recordings to be analyzed\n",
    "    ID = '%02d' % sub\n",
    "    bids_path = BIDSPath(subject=\"%02d\" % sub,\n",
    "                         session=\"02\", # change based on session being analyzed \n",
    "                         datatype=\"nirs\",\n",
    "                         root=\"C:\\\\Users\\\\abbie\\\\Box\\\\BRAiN Lab\\\\current projects\\\\esp-project\\\\esp-repeatability\\\\source data new glm\\\\\", # Change to where data set is located\n",
    "                         extension= \".snirf\")\n",
    "    raw_haemo, roi, cha, con, design_matrix= individual_analysis(bids_path, ID)\n",
    "    df_roi = pd.concat([df_roi, roi], ignore_index=True)\n",
    "    df_cha = pd.concat([df_cha, cha], ignore_index=True)\n",
    "    df_con = pd.concat([df_con, con], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize individual results\n",
    "\n",
    "grp_results = df_roi.query(\"Condition in ['speech', 'silence']\")\n",
    "grp_results = grp_results.query(\"Chroma in ['hbo']\")\n",
    "\n",
    "sns.catplot(x=\"Condition\", y=\"theta\", col=\"ID\", hue=\"ROI\", data=grp_results, col_wrap=5, errorbar=None, palette=\"muted\", height=4, s=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### GROUP-LEVEL RESULTS ###\n",
    "\n",
    "grp_results = df_roi.query(\"Condition in ['speech', 'silence']\")\n",
    "\n",
    "roi_model = smf.mixedlm(\"theta ~ -1 + ROI:Condition:Chroma\",\n",
    "                        grp_results, groups=grp_results[\"ID\"]).fit(method='nm')\n",
    "roi_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of channel and roi-level hemodynamic response amplitudes from analysis\n",
    "\n",
    "df_roi.to_csv(\"SS-tCCA_correction_model_ROI.csv\") # ROI-level\n",
    "df_cha.to_csv(\"SS-tCCA_correction_model_Chan.csv\") #Channel-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Regenerate the results from the original group model above; visualize group-level results\n",
    "grp_results = df_roi.query(\"Condition in ['speech','silence']\")\n",
    "roi_model = smf.mixedlm(\"theta ~ -1 + ROI:Condition:Chroma\",\n",
    "                        grp_results, groups=grp_results[\"ID\"]).fit(method='nm')\n",
    "\n",
    "df = statsmodels_to_results(roi_model)\n",
    "\n",
    "sns.catplot(x=\"Condition\", y=\"Coef.\", hue=\"ROI\", data=df.query(\"Chroma == 'hbo'\"), errorbar=None, palette=\"muted\", height=4, s=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Group topographic visualization \n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(10, 10),\n",
    "                         gridspec_kw=dict(width_ratios=[1, 1]))\n",
    "\n",
    "groups_single_chroma = dict(\n",
    "    HG = picks_pair_to_idx (raw_haemo.copy().pick(picks='hbo'),[[5,4],[5,3],[5,5],[6,4],[6,3],[6,5],[13,11],[13,10],[13,12],[14,11],[14,10],[14,12]] , on_missing = 'warning'),\n",
    "    PT = picks_pair_to_idx (raw_haemo.copy().pick(picks= 'hbo'),[[6,6],[6,7],[7,5],[7,7],[8,6],[8,7],[14,13],[14,14],[15,12],[15,14],[16,13],[16,14]], on_missing = 'warning'),\n",
    "    IFG = picks_pair_to_idx (raw_haemo.copy().pick(picks = 'hbo'), [[1,1],[2,1],[3,1],[4,1],[3,2],[4,2],[9,8],[10,8],[11,8],[12,8],[11,9],[12,9]], on_missing = 'warning'))\n",
    "\n",
    "    \n",
    "    # Cut down the dataframe just to the conditions we are interested in\n",
    "\n",
    "    \n",
    "ch_summary = df_cha.query(\"Condition in ['speech', 'silence']\")  #####Change these to your conditions####\n",
    "ch_summary = ch_summary.query(\"Chroma in ['hbo']\")\n",
    "\n",
    "# Run group level model and convert to dataframe\n",
    "ch_model = smf.mixedlm(\"theta ~ -1 + ch_name:Chroma:Condition\",\n",
    "                       ch_summary, groups=ch_summary[\"ID\"]).fit(method='nm')\n",
    "ch_model_df = statsmodels_to_results(ch_model)\n",
    "\n",
    "# Plot the two conditions for each ROI with both hbo and hbr\n",
    "\n",
    "# plot group topographic data for HbO\n",
    "plot_glm_group_topo(raw_haemo.copy().pick(picks=\"hbo\").pick(groups_single_chroma['IFG']),\n",
    "                    ch_model_df.query(\"Condition in ['speech']\"),                \n",
    "                    colorbar=False, axes=axes[0, 0],\n",
    "                    vlim=(0, 4), cmap=mpl.cm.Oranges)\n",
    "\n",
    "plot_glm_group_topo(raw_haemo.copy().pick(picks=\"hbo\").pick(groups_single_chroma['IFG']),\n",
    "                    ch_model_df.query(\"Condition in ['silence']\"),              \n",
    "                    colorbar=True, axes=axes[0, 1],\n",
    "                    vlim=(0, 4), cmap=mpl.cm.Oranges)\n",
    "\n",
    "plot_glm_group_topo(raw_haemo.copy().pick(picks=\"hbo\").pick(groups_single_chroma['HG']),\n",
    "                    ch_model_df.query(\"Condition in ['speech']\"),                \n",
    "                    colorbar=False, axes=axes[0, 0],\n",
    "                    vlim=(0, 4), cmap=mpl.cm.Oranges)\n",
    "\n",
    "plot_glm_group_topo(raw_haemo.copy().pick(picks=\"hbo\").pick(groups_single_chroma['HG']),\n",
    "                    ch_model_df.query(\"Condition in ['silence']\"),              \n",
    "                    colorbar=True, axes=axes[0, 1],\n",
    "                    vlim=(0, 4), cmap=mpl.cm.Oranges)\n",
    "\n",
    "plot_glm_group_topo(raw_haemo.copy().pick(picks=\"hbo\").pick(groups_single_chroma['PT']),\n",
    "                    ch_model_df.query(\"Condition in ['speech']\"),                \n",
    "                    colorbar=False, axes=axes[0, 0],\n",
    "                    vlim=(0, 4), cmap=mpl.cm.Oranges)\n",
    "\n",
    "plot_glm_group_topo(raw_haemo.copy().pick(picks=\"hbo\").pick(groups_single_chroma['PT']),\n",
    "                    ch_model_df.query(\"Condition in ['silence']\"),              \n",
    "                    colorbar=True, axes=axes[0, 1],\n",
    "                    vlim=(0, 4), cmap=mpl.cm.Oranges)\n",
    "\n",
    "\n",
    "# deoxygenated hemoglobin (HbR)\n",
    "ch_summary = df_cha.query(\"Condition in ['speech', 'silence']\")         \n",
    "ch_summary = ch_summary.query(\"Chroma in ['hbr']\")\n",
    "\n",
    "# Run group level model and convert to dataframe\n",
    "ch_model = smf.mixedlm(\"theta ~ -1 + ch_name:Chroma:Condition\",\n",
    "                       ch_summary, groups=ch_summary[\"ID\"]).fit(method='nm')\n",
    "ch_model_df = statsmodels_to_results(ch_model)\n",
    "\n",
    "\n",
    "# plot group topographic data for HbR\n",
    "plot_glm_group_topo(raw_haemo.copy().pick(picks=\"hbr\").pick(groups_single_chroma['IFG']),\n",
    "                    ch_model_df.query(\"Condition in ['speech']\"),                \n",
    "                    colorbar=False, axes=axes[0, 0],\n",
    "                    vlim=(0, 4), cmap=mpl.cm.Blues_r)\n",
    "\n",
    "plot_glm_group_topo(raw_haemo.copy().pick(picks=\"hbr\").pick(groups_single_chroma['IFG']),\n",
    "                    ch_model_df.query(\"Condition in ['silence']\"),               \n",
    "                    colorbar=True, axes=axes[0, 1],\n",
    "                    vlim=(0, 4), cmap=mpl.cm.Blues_r)\n",
    "\n",
    "plot_glm_group_topo(raw_haemo.copy().pick(picks=\"hbr\").pick(groups_single_chroma['HG']),\n",
    "                    ch_model_df.query(\"Condition in ['speech']\"),                \n",
    "                    colorbar=False, axes=axes[1, 0],\n",
    "                    vlim=(-10, 0), cmap=mpl.cm.Blues_r)\n",
    "plot_glm_group_topo(raw_haemo.copy().pick(picks=\"hbr\").pick(groups_single_chroma['HG']),\n",
    "                    ch_model_df.query(\"Condition in ['silence']\"),               \n",
    "                    colorbar=True, axes=axes[1, 1],\n",
    "                    vlim=(-10, 0), cmap=mpl.cm.Blues_r)\n",
    "\n",
    "plot_glm_group_topo(raw_haemo.copy().pick(picks=\"hbr\").pick(groups_single_chroma['PT']),\n",
    "                    ch_model_df.query(\"Condition in ['speech']\"),                \n",
    "                    colorbar=False, axes=axes[1, 0],\n",
    "                    vlim=(-10, 0), cmap=mpl.cm.Blues_r)\n",
    "plot_glm_group_topo(raw_haemo.copy().pick(picks=\"hbr\").pick(groups_single_chroma['PT']),\n",
    "                    ch_model_df.query(\"Condition in ['silence']\"),               \n",
    "                    colorbar=True, axes=axes[1, 1],\n",
    "                    vlim=(-10, 0), cmap=mpl.cm.Blues_r)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Contrast topographic visualization \n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(6, 6))\n",
    "con_summary = df_con.query(\"Chroma in ['hbo']\")\n",
    "\n",
    "# Run group level model and convert to dataframe\n",
    "con_model = smf.mixedlm(\"effect ~ -1 + ch_name:Chroma\",\n",
    "                        con_summary, groups=con_summary[\"ID\"]).fit(method='nm')\n",
    "con_model_df = statsmodels_to_results(con_model,\n",
    "                                      order=raw_haemo.copy().pick(\n",
    "                                          picks=\"hbo\").ch_names)\n",
    "\n",
    "#contrast plot for each ROI\n",
    "plot_glm_group_topo(raw_haemo.copy().pick(picks=\"hbo\").pick(groups_single_chroma['IFG']),\n",
    "                    con_model_df, colorbar=True, vlim=(-5, 5), axes=axes)\n",
    "\n",
    "plot_glm_group_topo(raw_haemo.copy().pick(picks=\"hbo\").pick(groups_single_chroma['HG']),\n",
    "                    con_model_df, colorbar=True, vlim=(-5, 5), axes=axes)\n",
    "\n",
    "plot_glm_group_topo(raw_haemo.copy().pick(picks=\"hbo\").pick(groups_single_chroma['PT']),\n",
    "                    con_model_df, colorbar=True, vlim=(-5, 5), axes=axes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "### Here, plot beta estimates on the cortical surface for specified conditions\n",
    "# Generate brain figure from channel-level data\n",
    "\n",
    "# Contrast model\n",
    "subjects_dir = mne.datasets.sample.data_path() / 'subjects'\n",
    "clim = dict(kind='value', pos_lims=(0, 8, 11))\n",
    "brain = plot_glm_surface_projection(raw_haemo.copy().pick(\"hbo\"),\n",
    "                                    con_model_df, clim=clim, view='dorsal',\n",
    "                                    colorbar=True, size=(800, 700), subjects_dir=subjects_dir)\n",
    "brain.add_text(0.05, 0.95, \"speech-silence\", 'title', font_size=16, color='k')\n",
    "\n",
    "# Run model code as above\n",
    "clim = dict(kind='value', pos_lims=(0, 11.5, 17))\n",
    "\n",
    "    ##########################################################\n",
    "    #   Pick conditions and list them in the line below   # \n",
    "    ##########################################################\n",
    "\n",
    "# Models for both conditions\n",
    "for idx, cond in enumerate(['speech','silence']):\n",
    "\n",
    "    # Run same model as explained in the sections above\n",
    "    ch_summary = df_cha.query(\"Condition in [@cond]\")\n",
    "    ch_summary = ch_summary.query(\"Chroma in ['hbo']\")\n",
    "    ch_model = smf.mixedlm(\"theta ~ -1 + ch_name\", ch_summary,\n",
    "                           groups=ch_summary[\"ID\"]).fit(method='nm')\n",
    "    model_df = statsmodels_to_results(ch_model, order=raw_haemo.copy().pick(\"hbo\").ch_names)\n",
    "\n",
    "    # Generate brain figure from data\n",
    "    brain = plot_glm_surface_projection(raw_haemo.copy().pick(\"hbo\"),\n",
    "                                        model_df, clim=clim, view='dorsal', value='Coef.',\n",
    "                                        colorbar=True, size=(800, 700), subjects_dir=subjects_dir)\n",
    "    brain.add_text(0.05, 0.95, cond, 'title', font_size=16, color='k')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
